<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Multiple Testing: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="../assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="../assets/styles.css">
<script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="manifest" href="../site.webmanifest">
<link rel="mask-icon" href="../safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>
        
      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>
      
      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='../aio.html';">Learner View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Multiple Testing
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Multiple Testing
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="../instructor/aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Multiple Testing
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../aio.html">Learner View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->
      
            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="What%20is%20multiple%20testing.html">1. What is multiple testing</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="Types%20of%20errors.html">2. Types of errors</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="Family-wise%20error%20rate.html">3. Family-wise error rate</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="False%20discovery%20rate.html">4. False discovery rate</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="Pairwise%20comparisons.html">5. Pairwise comparisons</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="Summary.html">6. Summary</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="References.html">7. References</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width resources">
<a href="../instructor/aio.html">See all in one page</a>
            

            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">
            
            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-What is multiple testing"><p>Content from <a href="What%20is%20multiple%20testing.html">What is multiple testing</a></p>
<hr>
<p>Last updated on 2024-06-25 |
        
        <a href="https://example.com/FIXME-template-source/edit/main/episodes/What%20is%20multiple%20testing.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is multiple testing?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Define multiple testing</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="section level1">
<h1 id="what-is-multiple-testing">What is multiple testing<a class="anchor" aria-label="anchor" href="#what-is-multiple-testing"></a>
</h1>
<p>Suppose the prevalence of a disease in the general population is 4%.
In this population, lives a group of individuals who have all been
exposed to air pollution. Concerned about their health, we decide to
embark on a quest to uncover whether being exposed to air pollution
influenced the risk of contracting this disease.</p>
<figure><img src="../fig/01-Disease-prevalence.png" alt="Figure_1: Disease prevalence in a population- Illustrating the proportion of individuals affected by the disease as 4% of the population" class="figure mx-auto d-block"><div class="figcaption">Figure_1: Disease prevalence in a population-
Illustrating the proportion of individuals affected by the disease as 4%
of the population</div>
</figure><div class="section level2">
<h2 id="setting-the-null-and-alternative-hypothesis">Setting the null and alternative hypothesis<a class="anchor" aria-label="anchor" href="#setting-the-null-and-alternative-hypothesis"></a>
</h2>
<p>We would like to conduct a hypothesis test to find out whether the
prevalence in the test group differs from the known 4%.</p>
<div class="section level3">
<h3 id="null-hypothesis-h_0">Null Hypothesis (<span class="math inline">\(H_0\)</span>)<a class="anchor" aria-label="anchor" href="#null-hypothesis-h_0"></a>
</h3>
<p>The prevalence of the disease within test group exposed to air
pollution is the same as the known prevalence in the general population
(4%). This means that the proportion of individuals exposed to air
pollution in the test group who have the disease is also 4%.</p>
</div>
<div class="section level3">
<h3 id="alternative-hypothesis-h_1">Alternative Hypothesis (<span class="math inline">\(H_1\)</span>)<a class="anchor" aria-label="anchor" href="#alternative-hypothesis-h_1"></a>
</h3>
<p>The prevalence of the disease within the test group exposed to air
pollution is different from the known prevalence in the general
population. This means that the proportion of individuals exposed to air
pollution in the test group who have the disease is either higher or
lower than 4%.</p>
</div>
</div>
<div class="section level2">
<h2 id="data-collection-and-testing">Data collection and testing<a class="anchor" aria-label="anchor" href="#data-collection-and-testing"></a>
</h2>
<p>We assemble a group of 100 individuals who have been exposed to air
pollution (test group) from the population and each individual is
carefully examined, checking for any signs of the disease. Out of the
100 individuals, we discover that 9 of them were indeed suffering from
the disease, so the <em>observed</em> proportion is 9%. This is
different from 4%, but we are not satisfied with just this knowledge,
since the observed difference in proportions could be due to chance. We
want to know if this prevalence of the disease within the group exposed
to air pollution was significantly different from the population’s
average, meaning that it’s very unlikely to observe this difference just
by chance. So, we decide to perform binomial test (please refer back to
binomial tests tutorial) <a href="%22https://sarahkaspar.github.io/biostatistics-course/03-binomial.html%22" class="external-link">The
binomial distribution</a>. With this test, we could compare the observed
prevalence within our group that has been exposed to air pollution to
the known prevalence in the entire population.</p>
<p>We set our significance level (α) beforehand, typically at 0.05, to
determine whether the results are statistically significant.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#For known parameters (n=100, p=0.04), we calculates the the chances of getting the 9 individuals that indeed suffered from the disease. </span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">100</span> <span class="co"># number of test persons</span></span>
<span><span class="va">p</span> <span class="op">=</span> <span class="fl">0.04</span> <span class="co"># Known prevalence of the disease in the general population</span></span>
<span><span class="fu">dbinom</span><span class="op">(</span>x<span class="op">=</span><span class="fl">9</span>, size<span class="op">=</span><span class="va">n</span>, prob<span class="op">=</span><span class="va">p</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] 0.01214746</code></pre>
</div>
<p>The P-value we get, is the probability of obtaining extreme outcome,
assuming that the null hypothesis is true. Therefore, the binomial test
calculates the probability of observing the obtained (9 persons with a
disease) or more extreme results assuming the null hypothesis is true.
If this probability is sufficiently low (below our chosen significance
level), we reject the null hypothesis in favor of the alternative
hypothesis.</p>
<p>The binomial test result (~0.012) reveals that the prevalence of the
disease among the individuals exposed to air pollution was indeed
significantly different from that of the population.</p>
</div>
<div class="section level2">
<h2 id="what-if-we-did-many-similar-experiments">What if we did many similar experiments?<a class="anchor" aria-label="anchor" href="#what-if-we-did-many-similar-experiments"></a>
</h2>
<p>Conducting a single study might not provide conclusive evidence due
to various factors such as sample variability, random chance, and other
unknown influences.</p>
<p>We decide to investigate the potential impact of air pollution on
disease prevalence in 200 various locations. We want to assess whether
there is a significant difference in disease rates between groups
exposed to air pollution and the average for the whole population.</p>
<p>We want to know how hypothesis testing works, when we perform it
simultaneously or in quick succession on many tests.</p>
<p>We therefore decide to simulate the scenario where we conduct 200
tests, each with a 5% chance (alpha = 0.05) of producing a significant
result (i.e., a p-value less than 0.05) even when the null hypothesis is
true.</p>
<p>Our null hypothesis in each location is that there is no real
difference in disease rates between the groups exposed to air pollution
and the average for the whole population.</p>
<figure><img src="../fig/Scenario_100%20individuals%20get%20tested%20for%20a%20disease.%20The%20disease%20prevalence%20is%200.04.%20The%20experiment%20is%20repeated%20200%20times.png" alt="Figure_2: A Scenario where 100 individuals get tested for a disease. The disease prevalence is 0.04. The experiment is repeated 200 times" class="figure mx-auto d-block"><div class="figcaption">Figure_2: A Scenario where 100 individuals get
tested for a disease. The disease prevalence is 0.04. The experiment is
repeated 200 times</div>
</figure><p>To do this, we write a program in R, which simulates study results
when the prevalence in the test group is 4% (null hypothesis is true).
We run these experiments to see what would happen if we kept doing tests
even when there was not actually any difference.</p>
<figure><img src="../fig/What%20is%20multiple%20testing-rendered-Simulating%20200%20test%20groups-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>We are interested in determining if the observed proportion
significantly deviates from the expected proportion (0.4) in either
direction (either higher or lower). As this is a two-tailed binomial
test, we needed to adjust the bounds for what is considered
“significant” based on the significance level of 0.05. We are interested
in the extreme tails of the distribution that contain 2.5% of the data
on each side.</p>
<p>We therefore use <code>qbinom()</code> function in this simulation to
calculate the quantiles of the binomial distribution corresponding to
the 2.5th and 97.5th percentiles. This gives us the bounds that would
contain 95% of the data under the null hypothesis. We then classify a
group as “significant” if the observed number of patients falls below
the 2.5th percentile or above the 97.5th percentile of the binomial
distribution.</p>
<p>In the resulting histogram, we find that even in a world where there
was no true difference in disease prevalence, about 5% of our simulated
experiments yielded statistically significant results purely by chance
(the red bars).</p>
<p>It is important to note that the significance level (α) that we
choose for each individual test directly impacts the rate of false
positives. This is basically the <strong>Comparison-Wise Error Rate
(CWER)</strong>, the probability of making a Type I error (false
positive) in a single hypothesis test. In our example, we have set
α=0.05 for each individual test, which means we are essentially saying
that we are willing to accept a 5% chance of making a false positive
error for each test, and this means that for 100 tests, we expect about
5 false positives.</p>
<p>By running this simulation multiple times, we can observe how often
we get false positive results when there should be none. This helps us
understand the likelihood of obtaining a significant result purely by
chance, even if there is no true effect or difference.</p>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#discussion1"></a>
</h3>
<div class="callout-content">
<ul>
<li>If we set α=0.01 for each individual test, which means we are
essentially saying that we are willing to accept a 1% chance of making a
false positive error for each test,what is the number of false positives
we should expect for 100 tests?</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">

</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="key-points">Key points<a class="anchor" aria-label="anchor" href="#key-points"></a>
</h3>
<ul>
<li>Through this exercise, we learn a valuable lesson about the dangers
of multiple testing.</li>
<li>We realize that without proper adjustments, the likelihood of
encountering false positives (rejecting a true null hypothesis) increase
with each additional comparison.</li>
<li>We need some additional control to make sure we found more hits than
expected by chance.</li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="so-what-is-multiple-testing">So what is multiple testing?<a class="anchor" aria-label="anchor" href="#so-what-is-multiple-testing"></a>
</h2>
<p>Multiple testing refers to the practice of conducting numerous
hypothesis tests simultaneously or repeatedly on the same data set. It
is typically motivated by the desire to explore different aspects of the
data or to investigate multiple hypotheses. Researchers employ multiple
tests to examine various relationships, comparisons, or associations
within their dataset, such as comparing means, proportions,
correlations, or other statistical analyses that involve hypothesis
testing.</p>
<div id="accordionInstructor1" class="accordion instructor-note accordion-flush">
<div class="accordion-item">
<button class="accordion-button instructor-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseInstructor1" aria-expanded="false" aria-controls="collapseInstructor1">
  <h3 class="accordion-header" id="headingInstructor1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="edit-2"></i></div> Instructor Note </h3>
</button>
<div id="collapseInstructor1" class="accordion-collapse collapse" aria-labelledby="headingInstructor1" data-bs-parent="#accordionInstructor1">
<div class="accordion-body">
<p>Inline instructor notes can help inform instructors of timing
challenges associated with the lessons. They appear in the “Instructor
View”</p>
</div>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>
</div></section><section id="aio-Types of errors"><p>Content from <a href="Types%20of%20errors.html">Types of errors</a></p>
<hr>
<p>Last updated on 2024-06-25 |
        
        <a href="https://example.com/FIXME-template-source/edit/main/episodes/Types%20of%20errors.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are false positives and false negatives and how do they
manifest in a confusion matrix?</li>
<li>What are some of real examples where false positives and false
negatives have different implications and consequences?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the concept of false positives and false negatives and
how they are represented in a confusion matrix</li>
<li>Analyse and discuss scnarios where false positives and false
negatives pose distinct challenges and implications</li>
<li>Highlight situations where minimizing each type of error is
crucial</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="section level1">
<h1 id="types-of-errors">Types of errors<a class="anchor" aria-label="anchor" href="#types-of-errors"></a>
</h1>
<p>In hypothesis testing, the evaluation of statistical significance
involves making decisions based on sample data. However, these decisions
are not without errors. In this tutorial, we will explore the concept of
errors in hypothesis testing (Type I and Type II errors), and their
implications.</p>
<div class="section level2">
<h2 id="type-i-error">Type I Error<a class="anchor" aria-label="anchor" href="#type-i-error"></a>
</h2>
<p>Type I error occurs when we reject a null hypothesis that is actually
true. For example, in our previous example where we conducted many
similar experiments, we experienced type I error by concluding that
exposure to air pollution has an effect on disease prevalence (rejecting
the null hypothesis) when it actually has no effect. Type I errors
represent false positives and can lead to incorrect conclusions,
potentially resulting in wasted resources or misguided decisions.</p>
</div>
<div class="section level2">
<h2 id="type-ii-error">Type II Error<a class="anchor" aria-label="anchor" href="#type-ii-error"></a>
</h2>
<p>Type II error occurs when we fail to reject a null hypothesis that is
actually false. For example, when we fail to conclude that exposure to
air pollution has an effect on disease prevalence (failing to reject the
null hypothesis) when it actually has a positive effect. Type II errors
represent false negatives and can result in missed opportunities or
overlooking significant effects.</p>
<p>One common way when this error occurs in the context of hypothesis
testing, is when a method with low <strong>statistical power</strong> is
chosen (if the sample size is small or the effect size (difference in
disease prevalence) is small). Statistical power refers to the
probability of correctly rejecting the null hypothesis when it is indeed
false. In simpler terms, it measures the likelihood of detecting a true
effect or difference if it exists. A test with high power is more likely
to detect a real effect, while a test with low power is more likely to
miss detecting a real effect, leading to a Type II error (false
negative).</p>
</div>
<div class="section level2">
<h2 id="confusion-matrix">Confusion Matrix<a class="anchor" aria-label="anchor" href="#confusion-matrix"></a>
</h2>
<p>In the context of hypothesis testing, we can conceptualize Type I and
Type II errors using a confusion matrix. The confusion matrix represents
the outcomes of hypothesis testing as True Positives (correctly
rejecting H0), False Positives (incorrectly rejecting H0), True
Negatives (correctly failing to reject H0), and False Negatives
(incorrectly failing to reject H0).</p>
<figure><img src="../fig/Figure%201%20Errors%20in%20hypothesis%20testing.png" alt="Figure_4: Errors in hypothesis testing and how they arise" class="figure mx-auto d-block"><div class="figcaption">Figure_4: Errors in hypothesis testing and how
they arise</div>
</figure>
</div>
</div>
<div class="section level1">
<h1 id="the-problem">The problem<a class="anchor" aria-label="anchor" href="#the-problem"></a>
</h1>
<p>In hypothesis testing, the occurrence of Type I and Type II errors
can have different implications depending on the context of the problem
being addressed. It is crucial to understand which errors are
problematic in which situation to be able to make informed decisions and
draw accurate conclusions from statistical analyses.</p>
<p>Type I errors, are particularly problematic in situations where the
cost or consequences of incorrectly rejecting a true null hypothesis are
high. Again if we refer back to our example, if we incorrectly conclude
that there is a significant difference in disease rates between the test
groups exposed to air pollution and the average for the whole population
when, in fact, there is no such difference, it could lead to misguided
policies or interventions targeting air pollution reduction. For
instance, authorities might implement costly environmental regulations
or public health measures based on erroneous conclusions. In this case,
the <strong>consequences</strong> include misallocation of resources,
leading to unnecessary financial burdens or societal disruptions.
Moreover, public trust in scientific findings and policy decisions may
be eroded if false positives lead to ineffective or burdensome
interventions.</p>
<p>Type II errors, are problematic when failing to detect a significant
effect has substantial consequences.If we fail to detect a significant
difference in disease rates between the test group and the population
average when there actually is a difference due to air pollution
exposure, it could result in overlooking a serious public health
concern. In this case, individuals living in polluted areas may continue
to suffer adverse health effects without receiving appropriate attention
or interventions. The <strong>consequences</strong> include increased
morbidity and mortality rates among populations exposed to high levels
of air pollution. Additionally, delayed or inadequate response to
environmental health risks may exacerbate inequalities in health
outcomes.</p>
<div class="section level2">
<h2 id="the-example-of-cancer-screening">The example of cancer screening<a class="anchor" aria-label="anchor" href="#the-example-of-cancer-screening"></a>
</h2>
<p>Cancer screening exemplifies a medical testing paradox, where the
interpretation of test results can be influenced by factors such as
disease prevalence, test sensitivity, and specificity.</p>
<p>Let us say that in a sample of 1000 women, 1% (10) have cancer, while
the remaining 99% (990) do not have cancer. This gives us the prevalence
of a disease. However, after testing, the test results show that out of
the 10 women with cancer, 9 receive a <strong>true positive</strong>
result (correctly identified as positive), and 1 receives a
<strong>false negative</strong> result (incorrectly identified as
negative). False negatives can delay the diagnosis and treatment of
cancer, allowing the disease to progress unchecked and potentially
reducing the effectiveness of treatment options. This can result in
poorer outcomes and decreased survival rates for patients. In addition,
out of the 990 women without cancer, 89 receive <strong>false
positive</strong> results (incorrectly identified as positive), and 901
receive <strong>true negative</strong> results (correctly identified as
negative). False positive can lead to unnecessary follow-up tests,
procedures, and treatments for individuals who do not have cancer. It
can cause anxiety, physical discomfort, and financial burden for
patients, as well as strain on healthcare resources.</p>
<figure><img src="../fig/cancer%20paradox.png" alt="Figure_5: A tree diagram describing the outcomes of a breast cancer test" class="figure mx-auto d-block"><div class="figcaption">Figure_5: A tree diagram describing the outcomes
of a breast cancer test</div>
</figure><p>We could interpret that:</p>
<ul>
<li><p>The <strong>probability</strong> that a woman who receives a
positive result actually has cancer is ≈ 1/10 ( 9/ (9 + 89)). This is
the positive predictive value (PPV) of the test.</p></li>
<li><p>The <strong>sensitivity</strong> of the test, which measures its
ability to detect the presence of disease is 90% (9/10 * 100). This
means that the false negative rate of the test is 10%.</p></li>
<li><p>The <strong>specificity</strong> of the test, which measures its
ability to correctly identify individuals without the disease is ≈ 91%
(901/990 * 100). Here, the false positive rate of the test is
9%.</p></li>
</ul>
<p>While the test may have high accuracy in terms of sensitivity and
specificity, the positive predictive value is relatively low due to the
low prevalence of the disease in the population. This means that a
positive result from the test does not strongly predict the presence of
the disease in an individual. Similarly, false positives and false
negatives can affect the negative predictive value of the test, which
measures its ability to correctly identify individuals who do not have
cancer. False negatives decrease the negative predictive value, while
false positives increase it, potentially leading to misinterpretation of
test results.</p>
<p>This example underscores the complexity of interpreting medical test
results and emphasizes the need to consider factors such as disease
prevalence, test sensitivity, and specificity in clinical
decision-making. Increasing sensitivity may reduce false negatives but
can also increase false positives, and vice versa. Thus, optimizing the
trade-off between sensitivity and specificity is crucial to minimize
false positives and false negatives while maximizing the accuracy of the
screening test.</p>
<div class="section level3">
<h3 id="what-do-we-learn">What do we learn?<a class="anchor" aria-label="anchor" href="#what-do-we-learn"></a>
</h3>
<p>In many real-world scenarios, there is a trade-off between Type I and
Type II errors, and the appropriate balance depends on the specific
goals and constraints of the problem. Reseachers may prioritize one over
the other based on the severity of the consequences. For example, in
cancer screenings, minimizing false negatives (Type II errors) is
typically prioritized to avoid missing potential cases of cancer, even
if it leads to an increase in false positives (Type I errors).</p>
<p>Effective evaluation of Type I and Type II errors necessitates a
comprehensive consideration of the associated costs, risks, and ethical
implications. This holistic approach enhances the validity and
reliability of research findings by ensuring that decisions regarding
hypothesis acceptance or rejection are informed not only by statistical
significance but also by the potential real-world consequences of both
false positives and false negatives. By carefully weighing these
factors, researchers can make informed decisions that minimize the
likelihood of erroneous conclusions while maximizing the practical
relevance and ethical soundness of their findings.</p>
<div id="accordionInstructor1" class="accordion instructor-note accordion-flush">
<div class="accordion-item">
<button class="accordion-button instructor-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseInstructor1" aria-expanded="false" aria-controls="collapseInstructor1">
  <h3 class="accordion-header" id="headingInstructor1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="edit-2"></i></div> Instructor Note </h3>
</button>
<div id="collapseInstructor1" class="accordion-collapse collapse" aria-labelledby="headingInstructor1" data-bs-parent="#accordionInstructor1">
<div class="accordion-body">
<p>Inline instructor notes can help inform instructors of timing
challenges associated with the lessons. They appear in the “Instructor
View”</p>
</div>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>
</div>
</div></section><section id="aio-Family-wise error rate"><p>Content from <a href="Family-wise%20error%20rate.html">Family-wise error rate</a></p>
<hr>
<p>Last updated on 2024-06-25 |
        
        <a href="https://example.com/FIXME-template-source/edit/main/episodes/Family-wise%20error%20rate.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is the family-wise error rate (FWER), and why is it important
in multiple testing scenarios?</li>
<li>How does the Bonferroni procedure adjust p-values to control the
FWER, and what are its limitations?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the concept of the family-wise error rate (FWER) and its
significance in multiple testing, including the implications of making
multiple comparisons without controlling for FWER.</li>
<li>Learn the Bonferroni procedure for adjusting p-values to maintain
the FWER at a specified level, and recognize when alternative methods
may be more appropriate or effective in controlling for multiple
comparisons.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>In statistical hypothesis testing, conducting multiple tests
simultaneously increases the likelihood of making at least one
false-positive error. In this episode, we will explore the family-wise
error rate (FWER), and discuss methods to account for multiple
comparisons, using practical examples.</p>
<section id="a-multi-hypothesis-testing-framework"><h2 class="section-heading">A Multi-Hypothesis Testing Framework<a class="anchor" aria-label="anchor" href="#a-multi-hypothesis-testing-framework"></a>
</h2>
<hr class="half-width">
<p>In multiple testing scenarios, we often have an overarching
hypothesis that encompasses several individual hypotheses, each
examining specific aspects or relationships within the data. This
approach allows us to explore various facets of the research question
comprehensively.</p>
<p>Going back to our study investigating the effects of air pollution on
the prevalence of a disease, the overarching hypothesis could be
formulated as follows:</p>
<p><em>Exposure to air pollution is associated with increased prevalence
of the disease</em></p>
<p>Under this overarching hypothesis, several individual hypotheses can
be formulated to examine different aspects of the relationship between
air pollution exposure and disease prevalence. These individual
hypotheses may focus on various pollutants, different health outcomes,
or specific populations.</p>
<p>An example using three individual null hypotheses:</p>
<p><strong><span class="math inline">\(H_{0,1}\)</span></strong>:
Exposure to particulate matter is not associated with increased disease
prevalence.</p>
<p><strong><span class="math inline">\(H_{0,2}\)</span></strong>:
Exposure to nitrogen dioxide is not associated with increased disease
prevalence.</p>
<p><strong><span class="math inline">\(H_{0,3}\)</span></strong>:
Long-term exposure to ozone (O3) is not associated with an increased
prevalence of the disease.</p>
<p>The three null hypotheses can be combined to the following overall
null hypothesis:</p>
<p><strong><span class="math inline">\(H_{0}\)</span></strong>: Air
pollution is not associated with an increased prevalence of the
disease.</p>
<div id="callout1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout<a class="anchor" aria-label="anchor" href="#callout1"></a>
</h3>
<div class="callout-content">
<p>As soon as one of the individual null hypotheses is rejected, we also
reject the overall null hypothesis. Rejecting the overall null
hypothesis would mean that at least one of the individual null
hypotheses is false. Therefore, we will want to make sure that we have
not a single false positive among our individual hypothesis tests.</p>
</div>
</div>
</div>
<figure><img src="../fig/Relationship%20between%20Overall%20Hypothesis%20and%20Individual%20Hypotheses.%20Effects%20of%20Air%20Pollution%20on%20Rdisease%20prevalence.png" alt="Figure_6: Relationship between Overall Hypothesis and Individual Hypotheses (Effects of Air Pollution on Disease Prevalence)" class="figure mx-auto d-block"><div class="figcaption">Figure_6: Relationship between Overall
Hypothesis and Individual Hypotheses (Effects of Air Pollution on
Disease Prevalence)</div>
</figure><p>In this illustration, each individual hypothesis delves into a
distinct facet of the overarching research inquiry, enabling us to
thoroughly examine the intricate connection between air pollution
exposure and disease prevalence. By scrutinizing the impacts of various
air pollutants on the disease, this method encourages a systematic
exploration of diverse factors and aids in revealing potential
associations or patterns within the data set.</p>
<p>Now, let us assume that after data collection, for hypothesis 1, we
find that 15 out of 100 individuals exposed to high levels of
particulate matter develop the disease, for hypothesis 2, 20 out of 100
individuals exposed to high levels of nitrogen dioxide develop the
disease and for hypothesis 3, 5 out of 100 individuals exposed to high
levels of ozone develop the disease.</p>
<p>Let us assume we conduct statistical tests for each of these
hypotheses, resulting in p-values for each test. For simplicity, let us
maintain our significance level at <span class="math inline">\(\alpha=0.05\)</span> for each individual test. We
can conduct binomial tests for each hypothesis and calculate the
p-values in R.</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Hypothesis 1: p = 0.0000
Hypothesis 2: p = 0.0285
Hypothesis 3: p = 0.1595</code></pre>
</div>
<div class="section level3">
<h3 id="the-probability-of-having-at-least-one-false-positive-among-m-tests-fwer">The probability of having at least one false positive among <span class="math inline">\(m\)</span> tests (FWER)<a class="anchor" aria-label="anchor" href="#the-probability-of-having-at-least-one-false-positive-among-m-tests-fwer"></a>
</h3>
<p>Let us assume each test has a probability <span class="math inline">\(\alpha\)</span> of producing a false positive, and
that we have <span class="math inline">\(m\)</span> independent
tests.</p>
<p>The probability that a single test does not produce a false positive
is calculated as: <span class="math display">\[1-\alpha\]</span></p>
<p>Since the tests are independent, the probability that none of the
<span class="math inline">\(m\)</span> tests produces a false positive
is calculated as: <span class="math display">\[(1-\alpha)^m\]</span></p>
<p>Therefore, the probability of at least one false positive is the
complement of the probability that none of the tests produce a false
positive, and is calculated as: <span class="math display">\[P(\text{at
least one false positive})=1−(1−\alpha)^m\]</span></p>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge1"></a>
</h3>
<div class="callout-content">
<ol style="list-style-type: decimal">
<li>In the above example, we have three different tests. Will the
probability of making one false positive still be 0.05?</li>
<li>What can we do to decrease the probability of any false
positive?</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<ol style="list-style-type: decimal">
<li>We can use R to calculate the probability of at least one false
positive for our example with three tests:</li>
</ol>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span></span>
<span></span>
<span><span class="fl">1</span> <span class="op">-</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">alpha</span><span class="op">)</span><span class="op">^</span><span class="va">m</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] 0.142625</code></pre>
</div>
<ol start="2" style="list-style-type: decimal">
<li>By decreasing the alpha.</li>
</ol>
</div>
</div>
</div>
</div>
</div>
</section><section id="the-bonferroni-correction"><h2 class="section-heading">The Bonferroni correction<a class="anchor" aria-label="anchor" href="#the-bonferroni-correction"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="adjusting-the-significance-level">Adjusting the significance level<a class="anchor" aria-label="anchor" href="#adjusting-the-significance-level"></a>
</h3>
<p>Now, to calculate the probability of having any false-positive within
the set of tests (also known as familywise error rate or FWER), we can
use methods such as the Bonferroni correction. This method adjust the
significance level for each test to control for multiple testing.</p>
<p>The Bonferroni procedure adjusts the significance level for each
individual test by dividing the desired overall significance level by
the number of tests conducted (m).</p>
<p><span class="math display">\[α_{\text{Bonf}}= α/m \]</span></p>
<p>Where:</p>
<p>α is the desired overall significance level (usually set to 0.05). m
is the number of hypothesis tests conducted.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">FWER</span> <span class="op">&lt;-</span> <span class="fl">0.05</span><span class="co"># Define the desired Family-wise error rate</span></span>
<span></span>
<span><span class="va">m</span> <span class="op">&lt;-</span> <span class="fu">length</span><span class="op">(</span><span class="va">p_values</span><span class="op">)</span><span class="co"># Calculate the number of hypothesis tests conducted (m)</span></span>
<span></span>
<span><span class="va">alpha_bonf</span> <span class="op">&lt;-</span> <span class="va">FWER</span> <span class="op">/</span> <span class="va">m</span> <span class="co"># Calculate Bonferroni adjusted significance level</span></span>
<span></span>
<span><span class="va">alpha_bonf</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] 0.01666667</code></pre>
</div>
<p>Since in our example above we have three tests (three hypotheses),
the Bonferroni corrected significance level is <span class="math inline">\(\alpha_{\text{bonf}} = 0.05/3 \approx
0.0167\)</span>.</p>
<div class="section level4">
<h4 id="interpretation">Interpretation<a class="anchor" aria-label="anchor" href="#interpretation"></a>
</h4>
<p>For each individual test, we compare the calculated p-value to this
adjusted significance level. If the p-value is less than or equal to
0.0167, we reject the null hypothesis for that test.</p>
<p>Based on the Bonferroni correction, we reject the null hypothesis for
Hypotheses 1, indicating significant associations between particulate
matter with disease prevalence. However, for Hypothesis 2 (nitrogen
dioxide exposure) and 3 (ozone exposure), we fail to reject the null
hypothesis, suggesting no significant association with disease
prevalence at the adjusted significance level. This adjustment for
multiple testing helps control the overall probability of making at
least one false-positive error across all tests conducted.</p>
<p>In this example, while the evidence supports associations between
certain air pollutants and disease prevalence, it does not provide
conclusive evidence to reject the overarching null hypothesis entirely.
Instead, it suggests a nuanced interpretation wherein the relationship
between air pollution exposure and disease prevalence may vary depending
on the specific pollutant considered. Therefore, further investigation
and analysis may be necessary to fully elucidate the relationship
between air pollution exposure and disease prevalence and to refine the
overarching null hypothesis accordingly. This could involve exploring
additional factors, conducting more comprehensive analyses, or
considering alternative statistical approaches to account for potential
confounding variables or sources of variability in the data.</p>
</div>
</div>
<div class="section level3">
<h3 id="adjusting-the-p-value">Adjusting the p-value<a class="anchor" aria-label="anchor" href="#adjusting-the-p-value"></a>
</h3>
<p>Instead of changing the significance level, another (equivalent)
calculation is adjusting the p-values obtained from individual
hypothesis tests, followed by comparing the adjusted p-values to the
desired FWER. With this procedure, we can reject those individual null
hypotheses that have a p-value below the desired FWER (<span class="math inline">\(p &lt; \text{FWER}\)</span>).</p>
<p><span class="math display">\[p_{\text{Bonf}}= p \times m\]</span></p>
<div id="challenge2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge2"></a>
</h3>
<div class="callout-content">
<ol style="list-style-type: decimal">
<li><p>Look up <code>p.adjust</code>. This function adjusts P-values for
Multiple Comparisons.</p></li>
<li><p>Using our previous example, can you adjust the p-values obtained
from individual hypothesis tests?</p></li>
<li><p>Which of the individual hypotheses can will be rejected at a
FWER=0.05?</p></li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<ol style="list-style-type: decimal">
<li>You can look up the function as follows:</li>
</ol>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">help</span><span class="op">(</span><span class="st">"p.adjust"</span><span class="op">)</span></span></code></pre>
</div>
<p>2.In R, one can adjust the p-values as follows:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">p.adjust</span><span class="op">(</span><span class="va">p_values</span>, method <span class="op">=</span> <span class="st">"bonferroni"</span><span class="op">)</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] 2.539669e-05 8.556039e-02 4.785324e-01</code></pre>
</div>
<ol start="3" style="list-style-type: decimal">
<li>We can check which of the individual hypotheses will be rejected at
a FWER=0.05:</li>
</ol>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">p.adjust</span><span class="op">(</span><span class="va">p_values</span>, method <span class="op">=</span> <span class="st">"bonferroni"</span><span class="op">)</span> <span class="op">&lt;</span> <span class="fl">0.05</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1]  TRUE FALSE FALSE</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>The conclusion is the same as when changing the significance level
for each test.</p>
<div id="accordionInstructor1" class="accordion instructor-note accordion-flush">
<div class="accordion-item">
<button class="accordion-button instructor-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseInstructor1" aria-expanded="false" aria-controls="collapseInstructor1">
  <h3 class="accordion-header" id="headingInstructor1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="edit-2"></i></div> Instructor Note </h3>
</button>
<div id="collapseInstructor1" class="accordion-collapse collapse" aria-labelledby="headingInstructor1" data-bs-parent="#accordionInstructor1">
<div class="accordion-body">
<p>Inline instructor notes can help inform instructors of timing
challenges associated with the lessons. They appear in the “Instructor
View”</p>
</div>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>
</section></section><section id="aio-False discovery rate"><p>Content from <a href="False%20discovery%20rate.html">False discovery rate</a></p>
<hr>
<p>Last updated on 2024-06-25 |
        
        <a href="https://example.com/FIXME-template-source/edit/main/episodes/False%20discovery%20rate.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How does correcting for the family-wise error rate (FWER) affect the
number of significant hits in large-scale data, such as RNA-Seq analysis
of 20,000 human genes?</li>
<li>What is the interpretation of a p-value histogram, and how can it be
used to assess the distribution of p-values in multiple testing
scenarios?</li>
<li>How can the Benjamini-Hochberg method be applied to control the
false discovery rate (FDR) in RNA-Seq data, and what are the benefits of
using this method over FWER correction?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Demonstrate how correcting for the family-wise error rate (FWER)
using methods like Bonferroni correction can lead to few or no
significant hits in large-scale testing scenarios.</li>
<li>Introduce the concept of p-value histograms, explain their
interpretation, and illustrate how they can be used to visualize the
distribution of p-values in multiple testing.</li>
<li>Explain the Benjamini-Hochberg method for controlling the false
discovery rate (FDR).</li>
<li>Provide practical examples and R code to apply the
Benjamini-Hochberg method to RNA-Seq data.</li>
<li>Discuss the advantages of controlling the FDR over FWER in the
context of large-scale genomic data.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="section level1">
<h1 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h1>
<p>In high-throughput experiments like RNA-Seq, we often conduct
thousands of statistical tests simultaneously. This large number of
tests increases the risk of false positives. While controlling the
family-wise error rate (FWER), the probability of making at least one
type I error, is one approach to address false positives, it can be too
conservative, leading to few or no significant results. An alternative
approach is to control the <strong>False Discovery Rate (FDR)</strong>,
the expected proportion of false positives among the rejected
hypotheses, which offers a balance between identifying true positives
and limiting false positives.</p>
<div class="section level2">
<h2 id="example-the-airway-dataset-in-r">Example: The Airway dataset in R<a class="anchor" aria-label="anchor" href="#example-the-airway-dataset-in-r"></a>
</h2>
<p>The Airway dataset contains gene expression data from a study
investigating the effects of dexamethasone (a corticosteroid medication)
on airway smooth muscle cells. The dataset is part of the airway package
in Bioconductor, a project that provides tools for the analysis and
comprehension of high-throughput genomic data.</p>
<p>In differentially expressed genes (DEGs) analysis, thousands of
statistical tests (one for each gene) are conducted, which increases the
chance of false positives. Using the airway dataset, we can decide to
analyze DEGs between treated and untreated samples. Here, the null
hypothesis would state that there is no difference in gene expression
between the two groups ( dexamethasone treated and untreated). The
<strong>Table 1</strong> below shows the first six rows of the generated
p-values for each gene, the data which, we are going use to see how
using FWER and FDR to controlling for false positive differ.</p>
<table class="table">
<caption>Table 1: P_Values for each analysed gene</caption>
<thead><tr class="header">
<th align="left">gene</th>
<th align="right">pvalue</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">ENSG00000000003</td>
<td align="right">0.0286636</td>
</tr>
<tr class="even">
<td align="left">ENSG00000000419</td>
<td align="right">0.0428183</td>
</tr>
<tr class="odd">
<td align="left">ENSG00000000457</td>
<td align="right">0.7874802</td>
</tr>
<tr class="even">
<td align="left">ENSG00000000460</td>
<td align="right">0.6972820</td>
</tr>
<tr class="odd">
<td align="left">ENSG00000000938</td>
<td align="right">0.6215698</td>
</tr>
<tr class="even">
<td align="left">ENSG00000000971</td>
<td align="right">0.0885597</td>
</tr>
</tbody>
</table>
</div>
<div class="section level2">
<h2 id="the-concept-of-p-value-histograms">The Concept of P-value Histograms<a class="anchor" aria-label="anchor" href="#the-concept-of-p-value-histograms"></a>
</h2>
<p>A p-value histogram is a graphical representation that displays the
distribution of p-values obtained from multiple hypothesis tests. When
conducting a large number of statistical tests, such as in genome-wide
association studies or RNA-Seq analysis, p-value histograms provide a
visual tool to assess the behavior and distribution of p-values across
all tests.</p>
<p>To create a p-value histogram, we plot the p-values on the x-axis and
the frequency (or count) of those p-values on the y-axis. This
visualization helps in understanding how the p-values are distributed
across the range from 0 to 1.</p>
<p>Here, we will use our generated p-values for each analysed gene to
create a histogram.</p>
<figure><img src="../fig/False%20discovery%20rate-rendered-unnamed-chunk-1-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>We will also find out how many genes were significantly
differentially expressed between the treated and untreated cells at
α=0.05 before we correct for type 1 error.</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>4655 is the number of significant differentially expressed genes before FWER correction</code></pre>
</div>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#discussion1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Now suppose we reject all tests with a p-value less than α=0.05. How
can we visually determine an estimate of the false discovery proportion
with a plot in r?</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">alpha</span> <span class="op">=</span> <span class="fl">0.05</span></span>
<span><span class="va">binw</span> <span class="op">=</span><span class="fl">0.01</span></span>
<span><span class="va">pi0</span> <span class="op">=</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu">mean</span><span class="op">(</span><span class="va">gene_pvalues</span><span class="op">$</span><span class="va">pvalue</span> <span class="op">&gt;</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">gene_pvalues</span>,</span>
<span>  <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">pvalue</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>binwidth <span class="op">=</span> <span class="va">binw</span>, boundary <span class="op">=</span> <span class="fl">0</span>,fill <span class="op">=</span> <span class="st">"lightblue"</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_hline</span><span class="op">(</span>yintercept <span class="op">=</span> <span class="va">pi0</span> <span class="op">*</span> <span class="va">binw</span> <span class="op">*</span> <span class="fu">nrow</span><span class="op">(</span><span class="va">gene_pvalues</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">alpha</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code></pre>
</div>
<figure><img src="../fig/False%20discovery%20rate-rendered-unnamed-chunk-4-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
</div>
<p>Notice that there are many null hypotheses that appear at low
p-values. Therefore, indiscriminately declaring all p-values less than
0.05 as significant will lead to a high number of false discoveries.
Additionally, some true alternative hypotheses may have high p-values,
leading to missed detections (false negatives) that our test cannot
identify.</p>
<div class="section level3">
<h3 id="interpretation-of-p-value-histograms">Interpretation of P-value Histograms<a class="anchor" aria-label="anchor" href="#interpretation-of-p-value-histograms"></a>
</h3>
<p>A p-value histogram helps identify patterns that might indicate
issues or meaningful findings in our data. If all the null hypotheses
are true (i.e., there is no effect), p-values should follow a uniform
distribution. This means the histogram should show a relatively flat
distribution of p-values across the range from 0 to 1 (<strong>Figure
8</strong>).</p>
<figure><img src="../fig/null_pvalues.png" alt="Figure_8: How p-values would look like if most or all our hypotheses were null" class="figure mx-auto d-block"><div class="figcaption">Figure_8: How p-values would look like if most
or all our hypotheses were null</div>
</figure><p>However, seeing this does not mean they actually are all null. It
means that at most a small percentage of hypotheses are non-null and
could be identified by a correction method. That is why applying an
uncorrected rule like “Accept everything with p-value less than 0.05” is
certain to give you many false discoveries.</p>
<p>If there are true effects present, you would expect to see an excess
of low p-values (close to 0) compared to what would be expected under a
uniform distribution (<strong>Figure 9</strong>). This indicates
potential significant findings. A large spike near zero can indicate
that many tests are finding significant results, suggesting the presence
of true positives.</p>
<figure><img src="../fig/reg_pvalues.png" alt="Figure_9: A peak close to 0 is where our alternative hypotheses live- along with some potential false positives" class="figure mx-auto d-block"><div class="figcaption">Figure_9: A peak close to 0 is where our
alternative hypotheses live- along with some potential false
positives</div>
</figure><p>A right-skewed distribution, with most p-values clustering towards 1
(<strong>Figure 10</strong>), might suggest that most tests are not
finding significant results, indicating that there may be few true
effects in the data.</p>
<figure><img src="../fig/conservative_pvalues.png" alt="Figure_10: Conservative p-values, something is wrong with your test!" class="figure mx-auto d-block"><div class="figcaption">Figure_10: Conservative p-values, something is
wrong with your test!</div>
</figure><p>P-values are designed to be uniform under the null hypothesis.
Therefore, if we observe deviations from this expectation, it should not
lead us to conclude that there are no significant hypotheses. Instead,
it suggests that there may be issues with our testing methodology. For
example, our test assumptions might not align with the actual data
distribution. It is possible that the test assumes a certain data
distribution (like continuous or normal), which doesn’t match the actual
characteristics of our data—such as it being discrete or highly
non-normal.</p>
<p>Some histogram like shown in <strong>Figure 11</strong> might exhibit
pronounced spikes at p-values near zero and near one.</p>
<figure><img src="../fig/bimodal_pvalues.png" alt="Figure_11: Bimodal p-values" class="figure mx-auto d-block"><div class="figcaption">Figure_11: Bimodal p-values</div>
</figure><p>This behavior often signals potential issues such as p-hacking or
deficiencies in experimental design. For instance, in the context of a
one-tailed test (e.g., assessing whether each gene increases expression
in response to a drug), p-values nearing 1 may indicate significance in
the opposite direction—instances where genes decreased their expression.
If you wish to identify such cases, consider switching to a two-sided
test. Alternatively, if these cases are irrelevant, filtering out
instances where estimates point in that direction could be
effective.</p>
<p>Moreover, in RNA-Seq data, for example, certain genes may show no
reads across all conditions, leading some differential expression tools
to return a p-value of 1. Identifying and filtering out such problematic
cases beforehand can help streamline our analysis without sacrificing
information.</p>
<p>Understanding the distribution of p-values can inform the choice of
multiple testing correction methods. For example, if there is an excess
of low p-values, controlling the false discovery rate (FDR) might be
more appropriate than controlling the family-wise error rate (FWER).
After applying a multiple testing correction (such as the
Benjamini-Hochberg method), a p-value histogram of the adjusted p-values
can help evaluate the effectiveness of the correction in controlling
false positives.</p>
</div>
</div>
<div class="section level2">
<h2 id="the-impact-of-correcting-for-the-family-wise-error-rate-fwer-using-bonferroni-correction">The impact of correcting for the family-wise error rate (FWER) using
Bonferroni correction<a class="anchor" aria-label="anchor" href="#the-impact-of-correcting-for-the-family-wise-error-rate-fwer-using-bonferroni-correction"></a>
</h2>
<p>Now, if we proceed to apply the Bonferroni method to correct the
family-wise error rate (FWER), we can then determine the number of genes
that show significant differential expression after the correction.</p>
<div class="codewrapper">
<h3 class="code-label">WARNING<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="warning" tabindex="0"><code>Warning: Removed 1 rows containing missing values (`geom_bar()`).</code></pre>
</div>
<figure><img src="../fig/False%20discovery%20rate-rendered-unnamed-chunk-5-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>706 is the number of significant differentially expressed genes after Bonferroni correction for FWER</code></pre>
</div>
<div class="section level3">
<h3 id="interpretation">Interpretation<a class="anchor" aria-label="anchor" href="#interpretation"></a>
</h3>
<p>Applying the Bonferroni correction in this example results in
<strong>706</strong> differentially expressed genes due to the stringent
threshold, demonstrating how FWER correction can be too conservative in
large-scale testing.</p>
</div>
</div>
<div class="section level2">
<h2 id="controlling-fdr-using-the-benjamini-hochberg-method">Controlling FDR Using the Benjamini-Hochberg Method<a class="anchor" aria-label="anchor" href="#controlling-fdr-using-the-benjamini-hochberg-method"></a>
</h2>
<p>The Benjamini-Hochberg (BH) method is a statistical procedure used to
control the FDR in multiple hypothesis testing, where the chance of
obtaining false positives increases. The BH method helps control the
proportion of false positives (false discoveries) among the rejected
hypotheses, thus providing a more balanced approach than traditional
methods like the <strong>Bonferroni correction</strong>, which can be
overly conservative. The BH procedure adjusts the p-values from multiple
tests to control the FDR. These adjusted p-values can be compared to a
significance threshold to determine which results are significant.</p>
<div class="section level3">
<h3 id="steps-of-the-benjamini-hochberg-procedure">Steps of the Benjamini-Hochberg Procedure<a class="anchor" aria-label="anchor" href="#steps-of-the-benjamini-hochberg-procedure"></a>
</h3>
<p>First the observed p-values are arranged in ascending order. Next,
ranks are assigned to the p-values, with the smallest p-value getting
rank 1, the next smallest rank 2, and so on. Then, for each p-value, the
BH critical value is calculated as;</p>
<p><span class="math display">\[\text{BH critical value} = \frac{i}{m}
\times Q\]</span></p>
<p>where, i is the rank, m is the total number of tests, and Q is the
desired FDR level (e.g., 0.05).</p>
<p>After this calculation, the largest p-value that is less than or
equal to its BH critical value is identified. This p-value and all
smaller p-values are considered significant. Optionally, one can adjust
the p-values to reflect the BH correction using software functions.</p>
<p>Now, let us continue with the generated p_values to apply the
Benjamini-Hochberg correction in r, and also plot the adjusted p values
for comparison.</p>
<div class="codewrapper">
<h3 class="code-label">WARNING<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="warning" tabindex="0"><code>Warning: Removed 1 rows containing missing values (`geom_bar()`).</code></pre>
</div>
<figure><img src="../fig/False%20discovery%20rate-rendered-unnamed-chunk-6-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>2357 is the number of significant differentially expressed genes that pass the FDR threshold</code></pre>
</div>
</div>
<div class="section level3">
<h3 id="interpretation-1">Interpretation<a class="anchor" aria-label="anchor" href="#interpretation-1"></a>
</h3>
<p>The Benjamini-Hochberg method controls the FDR, allowing for a
greater number of significant differentially expressed genes
(<strong>2357</strong>) compared to the Bonferroni correction
(<strong>706</strong>). This approach provides a more balanced and
powerful method for identifying true positives in large-scale data.</p>
</div>
</div>
<div class="section level2">
<h2 id="advantages-of-controlling-the-fdr-over-fwer-in-the-context-of-large-scale-genomic-data">Advantages of controlling the FDR over FWER in the context of
large-scale genomic data<a class="anchor" aria-label="anchor" href="#advantages-of-controlling-the-fdr-over-fwer-in-the-context-of-large-scale-genomic-data"></a>
</h2>
<ul>
<li><p>Higher statistical power: FDR control allows for higher power
compared to FWER control. In large-scale genomic studies, this means
detecting more true positives while still controlling false discoveries.
Since FDR methods are less stringent than FWER methods like Bonferroni
correction, they balance between controlling false discoveries and
maximizing true positives, reducing false negatives.</p></li>
<li><p>Consistency across studies: By setting a fixed FDR threshold
(e.g., 5%), results are more comparable across different studies and
meta-analyses, enhancing consistency in statistical inference.</p></li>
</ul>
<p>It is important to note that while FDR is preferred in many genomic
screens due to its ability to handle a large number of hypotheses, FWER
control remains appropriate in scenarios where minimizing any false
positives is critical. Each method has its place depending on the
research context and goals.</p>
<p>NB//: The aim of any multiple hypothesis test correction methods,
such as controlling the Family-Wise Error Rate (FWER) or the False
Discovery Rate (FDR), is to determine an appropriate threshold or cutoff
for declaring statistical significance across multiple tests or
hypotheses.</p>
</div>
<div class="section level2">
<h2 id="further-reading">Further reading<a class="anchor" aria-label="anchor" href="#further-reading"></a>
</h2>
<ul>
<li><a href="%22http://varianceexplained.org/statistics/interpreting-pvalue-histogram/%22" class="external-link">How
to interpret a p-value histogram</a></li>
</ul>
<div id="accordionInstructor1" class="accordion instructor-note accordion-flush">
<div class="accordion-item">
<button class="accordion-button instructor-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseInstructor1" aria-expanded="false" aria-controls="collapseInstructor1">
  <h3 class="accordion-header" id="headingInstructor1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="edit-2"></i></div> Instructor Note </h3>
</button>
<div id="collapseInstructor1" class="accordion-collapse collapse" aria-labelledby="headingInstructor1" data-bs-parent="#accordionInstructor1">
<div class="accordion-body">
<p>Inline instructor notes can help inform instructors of timing
challenges associated with the lessons. They appear in the “Instructor
View”</p>
</div>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>
</div></section><section id="aio-Pairwise comparisons"><p>Content from <a href="Pairwise%20comparisons.html">Pairwise comparisons</a></p>
<hr>
<p>Last updated on 2024-06-25 |
        
        <a href="https://example.com/FIXME-template-source/edit/main/episodes/Pairwise%20comparisons.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are pairwise comparisons, and how do they relate to the broader
concept of multiple testing in statistical analysis?</li>
<li>How can we effectively conduct and interpret pairwise comparisons to
make valid statistical inferences while controlling for the family-wise
error rate?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the Concept of Pairwise Comparisons</li>
<li>Learn how to conduct and interpret Pairwise Comparisons</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="section level1">
<h1 id="pairwise-comparisons">Pairwise comparisons<a class="anchor" aria-label="anchor" href="#pairwise-comparisons"></a>
</h1>
<p>Pairwise comparisons are a fundamental concept in statistical
analysis, allowing us to compare the means or proportions of multiple
groups or conditions. In this episode, we will explore the concept of
pairwise comparisons, their importance in statistical testing, and how
they relate to the broader context of multiple testing.</p>
<div class="section level2">
<h2 id="understanding-pairwise-comparisons">Understanding Pairwise Comparisons<a class="anchor" aria-label="anchor" href="#understanding-pairwise-comparisons"></a>
</h2>
<p>In our example of air pollution, fine particulate matter and other
pollutants can induce systemic inflammation in the body, leading to an
increase in circulating inflammatory markers like C-reactive protein
(CRP). Suppose we decide to divide the population into four groups based
on different levels of exposure to air pollution. Lets assume these
groups are as follow:</p>
<ul>
<li>Low exposure: Individuals living in rural areas with minimal
industrial activity and low traffic density.</li>
<li>Moderate exposure: Individuals living in suburban areas with some
industrial activity and moderate traffic density.</li>
<li>High exposure: Individuals living in urban areas with significant
industrial activity and high traffic density.</li>
<li>Very high exposure: Individuals living near industrial zones, major
highways, or heavily polluted urban areas.</li>
</ul>
<p><strong>Table 2</strong> shows the first six rows of CRP values of
individuals in the four exposure groups.</p>
<table class="table">
<caption>Table 2: CRP values of individuals in the four exposure
groups</caption>
<thead><tr class="header">
<th align="right">CRP</th>
<th align="left">Exposure</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">1.379049</td>
<td align="left">Low_exposure</td>
</tr>
<tr class="even">
<td align="right">2.039645</td>
<td align="left">Low_exposure</td>
</tr>
<tr class="odd">
<td align="right">5.617417</td>
<td align="left">Low_exposure</td>
</tr>
<tr class="even">
<td align="right">2.641017</td>
<td align="left">Low_exposure</td>
</tr>
<tr class="odd">
<td align="right">2.758576</td>
<td align="left">Low_exposure</td>
</tr>
<tr class="even">
<td align="right">5.930130</td>
<td align="left">Low_exposure</td>
</tr>
</tbody>
</table>
<p>In this case the “Exposure” column is a categorical variable with
four groups of exposure levels (Low_exposure, Moderate_exposure,
High_exposure, and Very_high_exposure).</p>
<figure><img src="../fig/Pairwise%20comparisons-rendered-unnamed-chunk-2-1.png" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Generally, from the above plot, as exposure level increases from low
to very high, we might expect to see a corresponding increase in the
median exposure level and higher median C-reactive protein (CRP)
values.</p>
<p>Our null hypothesis is that there is no difference in CRP amounts in
the different groups. Our significance levels is 0.05.</p>
<p>First we would do ANOVA, which would tell us whether there are any
differences between the groups.</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>             Df Sum Sq Mean Sq F value  Pr(&gt;F)    
Exposure      3   60.8  20.268   5.754 0.00086 ***
Residuals   196  690.4   3.523                    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<p>The ANOVA output above, shows statistically significant differences
among the means of the four exposure groups. It does this by comparing
the variability within each group to the variability between the groups.
We therefore reject the null hypothesis of equal means.</p>
</div>
<div class="section level2">
<h2 id="why-do-we-need-multiple-comparisons">Why do we need multiple comparisons?<a class="anchor" aria-label="anchor" href="#why-do-we-need-multiple-comparisons"></a>
</h2>
<p>ANOVA alone does not tell us which specific groups differ
significantly from each other. To determine this, we need to conduct
further analysis. Multiple comparison procedures (also known as post-hoc
tests) are used to compare pairs of groups in order to identify where
the differences lie. These tests provide more detailed information about
which specific group means are different from each other.</p>
<div class="section level3">
<h3 id="methods-for-performing-pairwise-comparisons">Methods for Performing Pairwise Comparisons<a class="anchor" aria-label="anchor" href="#methods-for-performing-pairwise-comparisons"></a>
</h3>
<p>Parametric methods, such as ANOVA post-hoc tests (e.g., Tukey’s HSD)
are used when assumptions of normality and homogeneity of variance are
met. Non-parametric methods, such as pairwise Wilcoxon tests, are
suitable when data do not meet the assumptions of parametric tests. In
R, performing pairwise comparisons is straightforward using built-in
functions and packages.</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>  Tukey multiple comparisons of means
    95% family-wise confidence level

Fit: aov(formula = CRP ~ Exposure, data = data)

$Exposure
                                           diff        lwr       upr     p adj
Moderate_exposure-Low_exposure        0.7240094 -0.2486521 1.6966710 0.2193881
High_exposure-Low_exposure            0.4233920 -0.5492695 1.3960536 0.6727404
Very_high_exposure-Low_exposure       1.5088066  0.5361450 2.4814681 0.0004795
High_exposure-Moderate_exposure      -0.3006174 -1.2732790 0.6720442 0.8539510
Very_high_exposure-Moderate_exposure  0.7847971 -0.1878644 1.7574587 0.1597266
Very_high_exposure-High_exposure      1.0854145  0.1127530 2.0580761 0.0219956</code></pre>
</div>
<p>We perform a Tukey post-hoc test using <strong>TukeyHSD()</strong> to
determine which specific exposure group means differ significantly from
each other. The results provide pairwise comparisons of group means
along with adjusted p-values to account for multiple comparisons.</p>
</div>
<div class="section level3">
<h3 id="interpreting-pairwise-comparison-results">Interpreting Pairwise Comparison Results<a class="anchor" aria-label="anchor" href="#interpreting-pairwise-comparison-results"></a>
</h3>
<p>Understanding significance levels and p-values obtained from pairwise
comparisons is essential for interpreting results accurately. The
p-values obtained from pairwise comparisons using the Tukey test are
adjusted to control the familywise error rate (FWER). Adjusted p-values
reflect the probability of observing a given result (or more extreme)
under the assumption that all null hypotheses are true, while accounting
for the number of comparisons made. Here, we interpret pairwise
comparison results with adjusted p-values from the Tukey test by
assessing whether the adjusted p-value is less than the chosen
significance level (α) (0.05). If the adjusted p-value is below the
significance level, we conclude that the observed difference is
statistically significant after correcting for multiple comparisons.</p>
<p>In some research scenarios, the comparisons between groups are
designed to answer specific, pre-defined research questions that are not
directly addressed by traditional ANOVA and subsequent p-value
adjustments. In this case, ANOVA and p-value adjustment don’t make any
sense.</p>
<p>For example, imagine we are conducting a study to investigate the
effect of different types of exercise (A, B, C, D) on three different
health outcomes (X, Y, Z). Our primary interest here is to compare each
type of exercise directly with respect to each health outcome, rather
than comparing all exercises together using ANOVA.</p>
<p>Probable research questions would be:</p>
<ul>
<li>Does exercise type A have a different effect than exercise type B on
health outcome X?</li>
<li>Is there a difference in the effect of exercise type A compared to
exercise type C on health outcome Y?</li>
<li>How does exercise type D compare to exercise type B in terms of
health outcome Z?</li>
</ul>
<p>In this case, instead of conducting a single ANOVA followed by
post-hoc tests to compare all exercises simultaneously, each comparison
is treated as a separate research question. The focus is on comparing
specific pairs of exercise types for each health outcome.</p>
<p>This means that we would analyze each comparison (e.g., A vs B for X,
A vs C for Y, D vs B for Z) independently using appropriate statistical
tests suited for comparing two groups (e.g., t-tests, Wilcoxon rank-sum
tests, etc.). Since these comparisons are independent and are addressing
distinct research questions, there is no need for ANOVA or adjustment of
p-values across comparisons.</p>
<p>We would then interpret the results of each pairwise comparison based
on their individual statistical significance and effect sizes relevant
to the specific research question posed. This approach allows for a
focused investigation into the differences between specific pairs of
exercise types and their effects on different health outcomes. This
tailored approach ensures that the statistical analysis aligns closely
with the specific objectives of the study, providing meaningful insights
into the relationships between variables of interest.</p>
</div>
</div>
<div class="section level2">
<h2 id="what-we-learn">What we learn<a class="anchor" aria-label="anchor" href="#what-we-learn"></a>
</h2>
<p>Pairwise comparisons involve comparing the means or proportions of
every possible pair of groups or conditions in a dataset. These
comparisons are used to identify specific differences between groups or
conditions that may not be apparent from overall statistical tests (like
the above case ANOVA). These comparisons play a crucial role in
statistical testing, particularly in the context of multiple
comparisons. They allow us to examine specific comparisons of interest
while controlling for the overall familywise error rate. The comparisons
are commonly used in various fields, including medicine, biology, social
sciences, and economics, to compare treatment groups, experimental
conditions, or categorical variables.</p>
</div>
<div class="section level2">
<h2 id="data-snooping-figure_6-data-snooping">Data snooping <img src="../fig/Data%20snooping.png" alt="Figure_6: Data snooping" class="figure"><a class="anchor" aria-label="anchor" href="#data-snooping-figure_6-data-snooping"></a>
</h2>
<p>In the context of the above analysis, data snooping refers to the
practice of exploring the data extensively, testing multiple hypotheses,
and making comparisons until finding a statistically significant result
or an interesting pattern. This can lead to overfitting the data or
finding false positives due to chance alone.</p>
<p>In our example, data snooping could involve testing multiple
comparisons between exposure groups until finding one that appears to be
statistically significant or interesting. For example, one might compare
only the “Very_high_exposure” group with the other groups, ignoring
other potential comparisons. This selective comparison increases the
likelihood of finding a significant result by chance alone.</p>
<p>Additionally, in some cases, we might decide not to perform all
tests. We could just visually inspect our plot, and only perform the
test that seems most promising when comparing the bars by eye. For
example, after observing the initial boxplot, we might want to conduct
numerous additional analyses or subgroup comparisons based on observed
patterns, without pre-specifying these comparisons. This approach can
lead to inflated Type I error rates (false positives) if corrections for
multiple testing are not applied.</p>
<p>Data snooping can influence decision-making by focusing only on
results that appear favorable or intriguing in the data. For instance,
if a particular exposure group shows a larger mean than others, a
decision might be made to focus solely on interventions or policies
targeting that group without considering the broader context or
potential confounding factors.</p>
</div>
<div class="section level2">
<h2 id="additional-resources">Additional resources<a class="anchor" aria-label="anchor" href="#additional-resources"></a>
</h2>
<p>For further reading and hands-on practice with pairwise comparisons
in R, refer to <a href="%22https://www.rdocumentation.org/%22" class="external-link">R
documentation on pairwise comparisons</a>, <a href="%22https://www.coursera.org/specializations/statistics%22" class="external-link">Applied
Statistics with R</a> and <a href="%22http://users.stat.umn.edu/~gary/book/fcdae.pdf%22" class="external-link">book by
Oehlert 2010</a> resources.</p>
<div id="accordionInstructor1" class="accordion instructor-note accordion-flush">
<div class="accordion-item">
<button class="accordion-button instructor-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseInstructor1" aria-expanded="false" aria-controls="collapseInstructor1">
  <h3 class="accordion-header" id="headingInstructor1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="edit-2"></i></div> Instructor Note </h3>
</button>
<div id="collapseInstructor1" class="accordion-collapse collapse" aria-labelledby="headingInstructor1" data-bs-parent="#accordionInstructor1">
<div class="accordion-body">
<p>Inline instructor notes can help inform instructors of timing
challenges associated with the lessons. They appear in the “Instructor
View”</p>
</div>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>
</div></section><section id="aio-Summary"><p>Content from <a href="Summary.html">Summary</a></p>
<hr>
<p>Last updated on 2024-06-25 |
        
        <a href="https://example.com/FIXME-template-source/edit/main/episodes/Summary.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="section level1">
<h1 id="error-rates">Error rates<a class="anchor" aria-label="anchor" href="#error-rates"></a>
</h1>
<p>We have seen that when dealing with multiple testing, it is crucial
to understand the different types of error rates that can be controlled.
<strong>Comparison-Wise Error Rate (CWER)</strong>, which is the
probability of making a Type I error (false positive) in any single
hypothesis test, does not account for the multiplicity of tests and can
lead to an increased number of false positives when many tests are
performed. <strong>Family-Wise Error Rate (FWER)</strong>, the
probability of making at least one Type I error among all the hypothesis
tests, is a stringent error rate control method, suitable for situations
where even one false positive is highly problematic. Methods like the
Bonferroni correction and Holm’s are often used to control FWER.
<strong>False Discovery Rate (FDR)</strong>, the expected proportion of
Type I errors among the rejected hypotheses, is less conservative than
FWER and is useful in large-scale testing scenarios, like genomic
studies, where some false positives are tolerable in exchange for higher
power to detect true positives. The Benjamini-Hochberg procedure is a
common method to control the FDR.</p>
</div>
<div class="section level1">
<h1 id="choosing-the-appropriate-error-rate">Choosing the appropriate error rate<a class="anchor" aria-label="anchor" href="#choosing-the-appropriate-error-rate"></a>
</h1>
<p>The choice of error rate to control depends on the research question
and the context of the study. For example, we could choose to control
CWER when testing the efficacy of a single new drug against a placebo in
a clinical trial, or when performing a single regression analysis to
test the relationship between two variables.</p>
<p>One would consider controlling FWER in clinical trials involving
multiple endpoints, where any false positive could lead to incorrect
conclusions about the drug’s safety or efficacy. in addition,
psychological experiments where multiple outcomes are tested and any
false positive could mislead theoretical interpretations would consider
controlling FWER.</p>
<p>The choise for controlling FDR is often considered in genome-wide
association studies (GWAS) analyzing thousands of genetic variants
simultaneously to identify potential associations with a disease, or in
RNA-Seq experiments aiming to identify differentially expressed genes
among tens of thousands of genes.</p>
</div>
<div class="section level1">
<h1 id="a-cook-book-to-navigate-multiple-testing-effectively">A Cook book to navigate multiple testing effectively<a class="anchor" aria-label="anchor" href="#a-cook-book-to-navigate-multiple-testing-effectively"></a>
</h1>
<p>To navigate multiple testing effectively, we should:</p>
<ol style="list-style-type: decimal">
<li><p>start by <strong>clearly defining our research question</strong>,
stating the specific hypothesis or set of hypotheses we aim to test, and
considering the implications of potential false positives and false
negatives.</p></li>
<li><p>Next, we <strong>decide on the appropriate error rate to
control</strong>, based on our research context and tolerance for Type I
errors. this means assessing how critical it is to avoid any false
positives (favoring FWER) versus allowing some false positives to
increase detection power (favoring FDR).</p></li>
<li><p>Finally, we <strong>select a suitable statistical method that
controls our chosen error rate</strong> and aligns with our data type
and experimental design, ensuring it is well-suited to the specifics of
our study.</p></li>
</ol>
<div id="accordionInstructor1" class="accordion instructor-note accordion-flush">
<div class="accordion-item">
<button class="accordion-button instructor-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseInstructor1" aria-expanded="false" aria-controls="collapseInstructor1">
  <h3 class="accordion-header" id="headingInstructor1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="edit-2"></i></div> Instructor Note </h3>
</button>
<div id="collapseInstructor1" class="accordion-collapse collapse" aria-labelledby="headingInstructor1" data-bs-parent="#accordionInstructor1">
<div class="accordion-body">
<p>Inline instructor notes can help inform instructors of timing
challenges associated with the lessons. They appear in the “Instructor
View”</p>
</div>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div></section><section id="aio-References"><p>Content from <a href="References.html">References</a></p>
<hr>
<p>Last updated on 2024-06-25 |
        
        <a href="https://example.com/FIXME-template-source/edit/main/episodes/References.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="section level1">
<h1 id="books">Books<a class="anchor" aria-label="anchor" href="#books"></a>
</h1>
<ul>
<li>Westfall, P. H., &amp; Young, S. S. (1993). Resampling-based
multiple testing: Examples and methods for p-value adjustment (Vol.
279). John Wiley &amp; Sons.</li>
<li>Hochberg, Y. (1987). Multiple comparison procedures. Wiley Series in
Probability and Statistics.</li>
<li>Dudoit, S., Van Der Laan, M. J., &amp; van der Laan, M. J. (2008).
Multiple testing procedures with applications to genomics
(pp. XXXIII-588). New York: Springer.</li>
</ul>
</div>
<div class="section level1">
<h1 id="articles">Articles<a class="anchor" aria-label="anchor" href="#articles"></a>
</h1>
<ul>
<li>Benjamini, Y., &amp; Hochberg, Y. (1995). Controlling the false
discovery rate: a practical and powerful approach to multiple testing.
Journal of the Royal statistical society: series B (Methodological),
57(1), 289-300..</li>
<li>Holm, S. (1979). A simple sequentially rejective multiple test
procedure. Scandinavian journal of statistics, 65-70.</li>
<li>Shaffer, J. P. (1995). Multiple hypothesis testing. Annual review of
psychology, 46(1), 561-584.</li>
<li>Storey, J. D., &amp; Tibshirani, R. (2003). Statistical significance
for genomewide studies. Proceedings of the National Academy of Sciences,
100(16), 9440-9445.</li>
<li>Pollard, K. S., Dudoit, S., &amp; van der Laan, M. J. (2005).
Multiple testing procedures: the multtest package and applications to
genomics. In Bioinformatics and computational biology solutions using R
and bioconductor (pp. 249-271). New York, NY: Springer New York.</li>
</ul>
</div>
<div class="section level1">
<h1 id="online-resources">Online Resources<a class="anchor" aria-label="anchor" href="#online-resources"></a>
</h1>
<ul>
<li><p><a href="%22https://biodatascience.github.io/compbio/test/multtest.html%22" class="external-link">Introduction
to multiple testing</a></p></li>
<li><p><a href="%22https://journal.r-project.org/archive/2014/RJ-2014-027/RJ-2014-027.pdf%22" class="external-link">sgof:
An R Package for Multiple Testing Problems</a></p></li>
</ul>
<div id="accordionInstructor1" class="accordion instructor-note accordion-flush">
<div class="accordion-item">
<button class="accordion-button instructor-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseInstructor1" aria-expanded="false" aria-controls="collapseInstructor1">
  <h3 class="accordion-header" id="headingInstructor1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="edit-2"></i></div> Instructor Note </h3>
</button>
<div id="collapseInstructor1" class="accordion-collapse collapse" data-bs-parent="#accordionInstructor1" aria-labelledby="headingInstructor1">
<div class="accordion-body">
<p>Inline instructor notes can help inform instructors of timing
challenges associated with the lessons. They appear in the “Instructor
View”</p>
</div>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>
        
        <a href="https://example.com/FIXME-template-source/edit/main/README.md" class="external-link">Edit on GitHub</a>
        
	
        | <a href="https://example.com/FIXME-template-source/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://example.com/FIXME-template-source/" class="external-link">Source</a></p>
				<p><a href="https://example.com/FIXME-template-source/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:carolyn.mukiri@embl.de">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">
        
        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>
        
        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.5" class="external-link">sandpaper (0.16.5)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.5" class="external-link">pegboard (0.7.5)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.3" class="external-link">varnish (1.0.3)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://FIXME-template-source.github.io/NA/instructor/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://FIXME-template-source.github.io/NA/instructor/aio.html",
  "identifier": "https://FIXME-template-source.github.io/NA/instructor/aio.html",
  "dateCreated": "2024-04-18",
  "dateModified": "2024-06-25",
  "datePublished": "2024-06-25"
}

  </script><script>
		feather.replace();
	</script>
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

